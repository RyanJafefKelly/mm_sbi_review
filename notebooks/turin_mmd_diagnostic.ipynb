{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "01a61f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax.numpy as jnp\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from mm_sbi_review.examples.turin import (\n",
    "    turin,\n",
    "    compute_turin_summaries,\n",
    "    compute_turin_summaries_with_max,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6299e267",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_z/ms2f3nmn0bb7wk4py9_pz7900000gp/T/ipykernel_7936/2039045948.py:10: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  sum_net = torch.load(\"../data/turin_robust-sbi/sum_net.pkl\", map_location=\"cpu\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TurinSummary(\n",
       "  (lstm): LSTM(1, 4, batch_first=True)\n",
       "  (conv): Sequential(\n",
       "    (0): Conv1d(1, 8, kernel_size=(3,), stride=(3,))\n",
       "    (1): Conv1d(8, 16, kernel_size=(3,), stride=(3,))\n",
       "    (2): Conv1d(16, 32, kernel_size=(3,), stride=(3,))\n",
       "    (3): Conv1d(32, 64, kernel_size=(3,), stride=(3,))\n",
       "    (4): Conv1d(64, 8, kernel_size=(3,), stride=(3,))\n",
       "    (5): AvgPool1d(kernel_size=(2,), stride=(2,), padding=(0,))\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import types, sys\n",
    "\n",
    "sys.modules[\"networks\"] = types.ModuleType(\"networks\")\n",
    "sys.modules[\"networks.summary_nets\"] = types.ModuleType(\"networks.summary_nets\")\n",
    "\n",
    "from summary_nets import TurinSummary  # local definition\n",
    "\n",
    "sys.modules[\"networks.summary_nets\"].TurinSummary = TurinSummary\n",
    "\n",
    "sum_net = torch.load(\"../data/turin_robust-sbi/sum_net.pkl\", map_location=\"cpu\")\n",
    "sum_net.eval()  # inference mode → disables dropout / BN updates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eb4ef2f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def learnt_stats(x_tensor: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    x_tensor : (N, 801)  or (batch, N, 801)  real‑valued power (dB)\n",
    "    returns  : (batch, d) summary where d = 8 for TurinSummary\n",
    "    \"\"\"\n",
    "    if x_tensor.ndim == 2:  # single data set\n",
    "        x_tensor = x_tensor.unsqueeze(0)  # → (1, N, 801)\n",
    "\n",
    "    _, stat = sum_net(x_tensor)  # (batch, d)\n",
    "    return stat.squeeze(0)  # (d,) if batch==1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8eb473cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_obs_tensor = torch.tensor(\n",
    "    np.load(\"../data/turin_obs.npy\"), dtype=torch.float32\n",
    ").reshape(100, 801)\n",
    "x_obs = jnp.array(learnt_stats(x_obs_tensor).numpy())  # (d,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "233e768a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get NPE posterior samples\n",
    "N = 100\n",
    "B = 4e9\n",
    "Ns = 801\n",
    "\n",
    "# x_data_full = (np.load(\"../data/turin_obs.npy\")).reshape(N, 801)\n",
    "# x_data_full = torch.tensor(x_data_full, dtype=torch.float32)\n",
    "# x_obs = compute_turin_summaries_with_max(x_data_full, delta_f=(B / (Ns - 1)))\n",
    "# x_obs = jnp.array(x_obs)\n",
    "\n",
    "with open(\"../data/turin_theta_2000_tau0.npy\", \"rb\") as f:\n",
    "    npe_samples = np.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6573f906",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax.numpy as jnp\n",
    "import numpy as np\n",
    "from functools import partial\n",
    "\n",
    "\n",
    "# --- 1. helpers --------------------------------------------------------------\n",
    "def rbf_kernel(x, y, ell):\n",
    "    return jnp.exp(-jnp.sum((x - y) ** 2, axis=-1) / (2 * ell**2))\n",
    "\n",
    "\n",
    "def median_heuristic(x, batch=1_000):\n",
    "    \"\"\"Median of pairwise ℓ2 distances (memory-friendly).\"\"\"\n",
    "    n = x.shape[0]\n",
    "\n",
    "    def dists(i):\n",
    "        sl = slice(i * batch, min((i + 1) * batch, n))\n",
    "        a = x[sl, None, :]\n",
    "        return jnp.sqrt(jnp.sum((a - x[None, :, :]) ** 2, -1)).ravel()\n",
    "\n",
    "    return jnp.sqrt(\n",
    "        jnp.median(jnp.concatenate([dists(i) for i in range((n + batch - 1) // batch)]))\n",
    "        / 2.0\n",
    "    )\n",
    "    # return 1.0\n",
    "\n",
    "\n",
    "def unbiased_mmd(sims, x_obs, ell):\n",
    "    l = sims.shape[0]\n",
    "\n",
    "    k_xx = rbf_kernel(sims[:, None, :], sims[None, :, :], ell)  # (l,l)\n",
    "    k_xy = rbf_kernel(sims, x_obs[None, :], ell).reshape(l)  # (l,)\n",
    "    mmd2 = k_xx.sum() / (l**2) - 2.0 * k_xy.sum() / l + 1.0\n",
    "    # k_xx.sum() / m**2 - 2 * k_xy.sum() / m\n",
    "    return mmd2\n",
    "\n",
    "\n",
    "def biased_mmd2(sims, x_obs, ell):\n",
    "    \"\"\"\n",
    "    Squared MMD (biased) between\n",
    "        P = empirical on `sims` (m ≥ 1)\n",
    "        Q = point mass at `x_obs`  (n = 1)\n",
    "    using an RBF kernel with bandwidth `ell`.\n",
    "    Returns: scalar MMD^2.\n",
    "    \"\"\"\n",
    "    k_xx = rbf_kernel(sims[:, None, :], sims[None, :, :], ell).mean()  # E_P k(X,X')\n",
    "    k_yy = 1.0  # k(y,y) = 1\n",
    "    k_xy = rbf_kernel(sims, x_obs[None, :], ell).mean()  # E_P k(X,y)\n",
    "\n",
    "    return k_xx + k_yy - 2.0 * k_xy\n",
    "\n",
    "\n",
    "def biased_mmd(sims, x_obs, ell):\n",
    "    return jnp.sqrt(jnp.maximum(biased_mmd2(sims, x_obs, ell), 0.0))\n",
    "\n",
    "\n",
    "def mmd_with_median(x, y):\n",
    "    ell = median_heuristic(jnp.concatenate([x, y], axis=0))\n",
    "    return biased_mmd2(x, y, ell)\n",
    "\n",
    "\n",
    "# # convenience wrapper that does the length-scale search once\n",
    "# def mmd_with_median(x, y):\n",
    "#     ell = median_heuristic(jnp.concatenate([x, y], axis=0))\n",
    "#     return\n",
    "# d_mmd(x, y, ell)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "184db4ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_post_pred_sims = 25\n",
    "\n",
    "turin_sim = turin(B=B, Ns=Ns, N=N, tau0=0)\n",
    "\n",
    "\n",
    "# posterior predictive samples based on NPE\n",
    "\n",
    "# for i in range(min(npe_samples.shape[0], num_post_pred_sims)):\n",
    "#     theta_draws = npe_samples[i, :]\n",
    "#     theta_draws = torch.tensor(theta_draws)\n",
    "#     data = turin_sim(theta_draws)\n",
    "#     summaries = compute_turin_summaries_with_max(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f22ec116",
   "metadata": {},
   "outputs": [],
   "source": [
    "def posterior_predictive_summaries(theta_array, sim):\n",
    "    stats = []\n",
    "    for th in theta_array:\n",
    "        x_sim = sim(torch.tensor(th))  # (N, 801)\n",
    "        s = learnt_stats(x_sim).numpy()  # (d,)\n",
    "        stats.append(s)\n",
    "    return jnp.stack(stats, axis=0)  # (m, d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b9b7e539",
   "metadata": {},
   "outputs": [],
   "source": [
    "s_rep = posterior_predictive_summaries(\n",
    "    npe_samples[:num_post_pred_sims], turin_sim\n",
    ")  # (m, d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "93a47ad4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25, 8)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s_rep.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "50e2632b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ell = median_heuristic(jnp.concatenate([s_rep, x_obs[None, :]], axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "75ce3ae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "mmd_obs = biased_mmd(s_rep, x_obs, ell)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7a797f5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s_rep.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f640c0f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array(3.4201233, dtype=float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "501db448",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MMD̂ = 0.9324  |  critical 5 % = 0.3517  |  p = 0.000\n"
     ]
    }
   ],
   "source": [
    "import jax.random as random\n",
    "\n",
    "B_null = 100  # size of null distribution\n",
    "\n",
    "rng_key = random.PRNGKey(0)  # for reproducibility\n",
    "\n",
    "m = s_rep.shape[0]  # same size you used in the observed test\n",
    "\n",
    "\n",
    "def mmd_under_null(key):\n",
    "    key_theta, key_val, key_obs = random.split(key, 3)\n",
    "\n",
    "    # 1. draw *one* parameter θ*\n",
    "    idx = random.randint(key_theta, (), 0, npe_samples.shape[0])\n",
    "    theta_star = npe_samples[idx]\n",
    "\n",
    "    # 2. simulate m validation data sets and 1 \"observed\" data set\n",
    "    val_summaries = []\n",
    "    for _ in range(m):\n",
    "        x_val = turin_sim(torch.tensor(theta_star))\n",
    "        val_summaries.append(jnp.array(learnt_stats(x_val)))\n",
    "    x_obs_sim = turin_sim(torch.tensor(theta_star))\n",
    "    s_obs_sim = learnt_stats(x_obs_sim)\n",
    "    s_obs_sim = jnp.array(s_obs_sim)\n",
    "\n",
    "    s_val = jnp.stack(val_summaries, axis=0)  # shape (m,d)\n",
    "    s_obs_1 = s_obs_sim[None, :]  # shape (1,d)\n",
    "\n",
    "    return biased_mmd(s_val, s_obs_1, ell)  # same estimator you used before\n",
    "\n",
    "\n",
    "keys = random.split(rng_key, num=B_null)\n",
    "mmd_null = jnp.array([mmd_under_null(k) for k in keys])\n",
    "\n",
    "crit = jnp.quantile(mmd_null, 0.95)  # 5 % test\n",
    "pval = (mmd_null >= mmd_obs).mean()\n",
    "\n",
    "print(f\"MMD̂ = {mmd_obs:.4f}  |  critical 5 % = {crit:.4f}  |  p = {pval:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6d50dda0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([0.30802575, 0.28400996, 0.13446763, 0.09258758, 0.1934053 ,\n",
       "       0.12388543, 0.05393685, 0.2165058 , 0.18614213, 0.1962845 ,\n",
       "       0.24966933, 0.18680985, 0.10587656, 0.14259276, 0.16471262,\n",
       "       0.16560115, 0.18295273, 0.15027446, 0.11998314, 0.5646854 ,\n",
       "       0.06623639, 0.0687905 , 0.26325855, 0.2393258 , 0.0974167 ,\n",
       "       0.20745835, 0.46021914, 0.10612173, 0.03889889, 0.05787214,\n",
       "       0.29299173, 0.15531643, 0.16331421, 0.14880526, 0.05029652,\n",
       "       0.16297881, 0.17082901, 0.27280942, 0.07253072, 0.0591012 ,\n",
       "       0.1432109 , 0.12280346, 0.16192138, 0.13050681, 0.07665238,\n",
       "       0.07636491, 0.13040721, 0.07866861, 0.08689074, 0.09557786,\n",
       "       0.07862768, 0.06823108, 0.22895913, 0.09558472, 0.10791457,\n",
       "       0.12474655, 0.18222772, 0.30661982, 0.15387717, 0.2298651 ,\n",
       "       0.18580273, 0.197709  , 0.07605127, 0.14670312, 0.29901814,\n",
       "       0.10876349, 0.28155777, 0.5534229 , 0.12415505, 0.06927057,\n",
       "       0.08272585, 0.07554328, 0.32259375, 0.53173053, 0.12898484,\n",
       "       0.23662479, 0.17588633, 0.11706027, 0.1707484 , 0.3506072 ,\n",
       "       0.04711724, 0.1308999 , 0.1705535 , 0.05840015, 0.24091373,\n",
       "       0.21903919, 0.20214932, 0.14202733, 0.23387806, 0.37288514,\n",
       "       0.07579535, 0.123675  , 0.18639077, 0.09422942, 0.23374881,\n",
       "       0.14885493, 0.19755186, 0.1166144 , 0.17936411, 0.16381963],      dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mmd_null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b21f945",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "311aa3a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array(0.93239707, dtype=float32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mmd_obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b02c4d2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([0.30802575, 0.28400996, 0.13446763, 0.09258758, 0.1934053 ,\n",
       "       0.12388543, 0.05393685, 0.2165058 , 0.18614213, 0.1962845 ,\n",
       "       0.24966933, 0.18680985, 0.10587656, 0.14259276, 0.16471262,\n",
       "       0.16560115, 0.18295273, 0.15027446, 0.11998314, 0.5646854 ,\n",
       "       0.06623639, 0.0687905 , 0.26325855, 0.2393258 , 0.0974167 ,\n",
       "       0.20745835, 0.46021914, 0.10612173, 0.03889889, 0.05787214,\n",
       "       0.29299173, 0.15531643, 0.16331421, 0.14880526, 0.05029652,\n",
       "       0.16297881, 0.17082901, 0.27280942, 0.07253072, 0.0591012 ,\n",
       "       0.1432109 , 0.12280346, 0.16192138, 0.13050681, 0.07665238,\n",
       "       0.07636491, 0.13040721, 0.07866861, 0.08689074, 0.09557786,\n",
       "       0.07862768, 0.06823108, 0.22895913, 0.09558472, 0.10791457,\n",
       "       0.12474655, 0.18222772, 0.30661982, 0.15387717, 0.2298651 ,\n",
       "       0.18580273, 0.197709  , 0.07605127, 0.14670312, 0.29901814,\n",
       "       0.10876349, 0.28155777, 0.5534229 , 0.12415505, 0.06927057,\n",
       "       0.08272585, 0.07554328, 0.32259375, 0.53173053, 0.12898484,\n",
       "       0.23662479, 0.17588633, 0.11706027, 0.1707484 , 0.3506072 ,\n",
       "       0.04711724, 0.1308999 , 0.1705535 , 0.05840015, 0.24091373,\n",
       "       0.21903919, 0.20214932, 0.14202733, 0.23387806, 0.37288514,\n",
       "       0.07579535, 0.123675  , 0.18639077, 0.09422942, 0.23374881,\n",
       "       0.14885493, 0.19755186, 0.1166144 , 0.17936411, 0.16381963],      dtype=float32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mmd_null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "70951dd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b: 0\n",
      "b: 1\n",
      "b: 2\n",
      "b: 3\n",
      "b: 4\n",
      "b: 5\n",
      "b: 6\n",
      "b: 7\n",
      "b: 8\n",
      "b: 9\n",
      "b: 10\n",
      "b: 11\n",
      "b: 12\n",
      "b: 13\n",
      "b: 14\n",
      "b: 15\n",
      "b: 16\n",
      "b: 17\n",
      "b: 18\n",
      "b: 19\n",
      "b: 20\n",
      "b: 21\n",
      "b: 22\n",
      "b: 23\n",
      "b: 24\n",
      "MMD^2_obs=2.70869  MMD_obs=1.64581  crit@0.95=2.13876  p=0.000\n"
     ]
    }
   ],
   "source": [
    "# --- MMD misspecification diagnostic (paper-compliant) -----------------------\n",
    "# Prior-predictive summaries -> whiten (fit on validation) -> multi-kernel RBF\n",
    "# Null via independent draws from p(z|M); first sample kept large and fixed.\n",
    "\n",
    "import numpy as np, torch\n",
    "\n",
    "# 0) Make sure nets/tensors live on same device as the simulator\n",
    "_dev = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "try:\n",
    "    sum_net.to(_dev)\n",
    "except NameError:\n",
    "    pass\n",
    "try:\n",
    "    x_obs_tensor = x_obs_tensor.to(_dev)\n",
    "except NameError:\n",
    "    raise RuntimeError(\"x_obs_tensor not found; load your observed data first.\")\n",
    "\n",
    "# 1) Prior from run_turin.py (BoxUniform bounds)\n",
    "_PRIOR_LOW = np.array([1e-9, 1e-9, 1e7, 1e-10], dtype=np.float64)\n",
    "_PRIOR_HIGH = np.array([1e-8, 1e-8, 5e9, 1e-9], dtype=np.float64)\n",
    "_rng = np.random.default_rng(0)\n",
    "\n",
    "\n",
    "def prior_sample(n: int) -> np.ndarray:\n",
    "    return _rng.uniform(_PRIOR_LOW, _PRIOR_HIGH, size=(n, 4))\n",
    "\n",
    "\n",
    "# 2) Summaries via your learned network (expects dB power)\n",
    "@torch.no_grad()\n",
    "def sim_summaries(num: int) -> np.ndarray:\n",
    "    out = []\n",
    "    thetas = prior_sample(num)\n",
    "    for th in thetas:\n",
    "        x = turin_sim(torch.tensor(th, dtype=torch.float32, device=_dev))  # (N,801)\n",
    "        s = learnt_stats(x).detach().to(\"cpu\").numpy()\n",
    "        out.append(s)\n",
    "    return np.asarray(out, dtype=np.float64)  # (num, d)\n",
    "\n",
    "\n",
    "# 3) Whitening fit on validation only\n",
    "def whiten_fit(Z: np.ndarray, eps: float = 1e-6):\n",
    "    mu = Z.mean(0)\n",
    "    C = np.cov(Z, rowvar=False) + eps * np.eye(Z.shape[1])\n",
    "    L = np.linalg.cholesky(C)\n",
    "    return mu, L\n",
    "\n",
    "\n",
    "def whiten_apply(Z: np.ndarray, mu: np.ndarray, L: np.ndarray) -> np.ndarray:\n",
    "    return np.linalg.solve(L, (Z - mu).T).T\n",
    "\n",
    "\n",
    "# 4) Multi-kernel RBF (biased MMD^2, valid for N=1)\n",
    "def rbf_sum(X: np.ndarray, Y: np.ndarray, sigmas: np.ndarray) -> np.ndarray:\n",
    "    # X:(n,d), Y:(m,d)\n",
    "    d2 = ((X[:, None, :] - Y[None, :, :]) ** 2).sum(-1)  # (n,m)\n",
    "    K = np.exp(-0.5 * d2[:, :, None] / (sigmas[None, None, :] ** 2)).sum(-1)\n",
    "    return K\n",
    "\n",
    "\n",
    "def mmd2_biased(X: np.ndarray, Y: np.ndarray, sigmas: np.ndarray) -> float:\n",
    "    kxx = rbf_sum(X, X, sigmas).mean()\n",
    "    kyy = rbf_sum(Y, Y, sigmas).mean()\n",
    "    kxy = rbf_sum(X, Y, sigmas).mean()\n",
    "    return float(kxx + kyy - 2.0 * kxy)\n",
    "\n",
    "\n",
    "# 5) Fixed kernel widths from validation only (no peeking at observed)\n",
    "def median_pairwise(Z: np.ndarray, cap: int = 2000) -> float:\n",
    "    if Z.shape[0] > cap:\n",
    "        Z = Z[_rng.choice(Z.shape[0], size=cap, replace=False)]\n",
    "    d = np.sqrt(((Z[:, None, :] - Z[None, :, :]) ** 2).sum(-1)).ravel()\n",
    "    return np.median(d[d > 0])\n",
    "\n",
    "\n",
    "def make_sigmas(Z_val_w: np.ndarray) -> np.ndarray:\n",
    "    med = max(median_pairwise(Z_val_w), 1e-12)\n",
    "    return med * np.array([0.5, 1.0, 2.0, 4.0, 8.0], dtype=np.float64)\n",
    "\n",
    "\n",
    "# ------------------------------ Run the test ---------------------------------\n",
    "M_val = 100  # prior-predictive validation size\n",
    "B_null = 25  # null replicates\n",
    "alpha = 0.05\n",
    "\n",
    "# A) Validation summaries from p(z|M)\n",
    "Z_val = sim_summaries(M_val)  # (M,d)\n",
    "mu, L = whiten_fit(Z_val)\n",
    "Z_val_w = whiten_apply(Z_val, mu, L)\n",
    "\n",
    "# B) Observed summaries (N may be 1)\n",
    "z_obs = learnt_stats(x_obs_tensor).detach().to(\"cpu\").numpy()[None, ...]\n",
    "Z_obs_w = whiten_apply(z_obs, mu, L)\n",
    "\n",
    "# C) Multi-kernel widths from validation only\n",
    "sigmas = make_sigmas(Z_val_w)\n",
    "\n",
    "# D) Observed statistic\n",
    "mmd2_obs = mmd2_biased(Z_val_w, Z_obs_w, sigmas)\n",
    "\n",
    "# E) Null: independent second sample from p(z|M), size N, using the fixed large first set\n",
    "N = Z_obs_w.shape[0]\n",
    "Kxx_const = rbf_sum(Z_val_w, Z_val_w, sigmas).mean()  # one-time cost\n",
    "mmd2_null = np.empty(B_null, dtype=np.float64)\n",
    "for b in range(B_null):\n",
    "    print(f\"b: {b}\")\n",
    "    Z_b = whiten_apply(sim_summaries(N), mu, L)\n",
    "    kyy = rbf_sum(Z_b, Z_b, sigmas).mean()\n",
    "    kxy = rbf_sum(Z_val_w, Z_b, sigmas).mean()\n",
    "    mmd2_null[b] = Kxx_const + kyy - 2.0 * kxy\n",
    "\n",
    "crit = np.quantile(mmd2_null, 1.0 - alpha)\n",
    "pval = float(np.mean(mmd2_null >= mmd2_obs))\n",
    "\n",
    "print(\n",
    "    f\"MMD^2_obs={mmd2_obs:.6g}  MMD_obs={np.sqrt(mmd2_obs):.6g}  \"\n",
    "    f\"crit@{1-alpha:.2f}={crit:.6g}  p={pval:.3f}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "609f8fc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.91406661, 1.65363886, 1.02260941, 1.80480186, 0.9922519 ,\n",
       "       1.91380868, 0.90085011, 0.70903236, 1.51323068, 1.89239709,\n",
       "       2.19312863, 0.91823997, 1.89758444, 1.7354356 , 2.20557598,\n",
       "       1.20414721, 1.81721313, 1.89032247, 1.92128648, 1.55331989,\n",
       "       0.81432782, 1.02096912, 1.31130663, 1.5232953 , 1.64831147])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mmd2_null"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
