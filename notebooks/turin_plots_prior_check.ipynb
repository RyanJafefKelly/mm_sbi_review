{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NOTE: NOT INCLUDED IN PAPER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mm_sbi_review.examples.turin import turin, compute_turin_summaries\n",
    "import torch\n",
    "import numpy as np\n",
    "from sbi.inference import NLE\n",
    "from sbi.utils import BoxUniform\n",
    "from mm_sbi_review.examples.turin import TurinSummary\n",
    "import matplotlib.pyplot as plt\n",
    "from sbi.utils.user_input_checks import (\n",
    "    check_sbi_inputs,\n",
    "    process_prior,\n",
    "    process_simulator,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The expanded size of the tensor (12) must match the existing size (9) at non-singleton dimension 0.  Target sizes: [12].  Tensor sizes: [9]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 29\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# test_theta = torch.tensor([10 ** (-8.4), 7.8e-9, 1e9, 2.8e-10])\u001b[39;00m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m# x_sim = simulator(test_theta)\u001b[39;00m\n\u001b[1;32m     25\u001b[0m prior \u001b[38;5;241m=\u001b[39m BoxUniform(\n\u001b[1;32m     26\u001b[0m     low\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mtensor([\u001b[38;5;241m1e-9\u001b[39m, \u001b[38;5;241m1e-9\u001b[39m, \u001b[38;5;241m1e7\u001b[39m, \u001b[38;5;241m1e-10\u001b[39m]),\n\u001b[1;32m     27\u001b[0m     high\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mtensor([\u001b[38;5;241m1e-8\u001b[39m, \u001b[38;5;241m1e-8\u001b[39m, \u001b[38;5;241m5e9\u001b[39m, \u001b[38;5;241m1e-9\u001b[39m]),\n\u001b[1;32m     28\u001b[0m )\n\u001b[0;32m---> 29\u001b[0m \u001b[43mcheck_sbi_inputs\u001b[49m\u001b[43m(\u001b[49m\u001b[43msimulator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprior\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     31\u001b[0m inference \u001b[38;5;241m=\u001b[39m NLE(prior)\n\u001b[1;32m     32\u001b[0m proposal \u001b[38;5;241m=\u001b[39m prior\n",
      "File \u001b[0;32m~/python_projects/mm_sbi_review/.venv/lib/python3.11/site-packages/sbi/utils/user_input_checks.py:659\u001b[0m, in \u001b[0;36mcheck_sbi_inputs\u001b[0;34m(simulator, prior)\u001b[0m\n\u001b[1;32m    657\u001b[0m theta \u001b[38;5;241m=\u001b[39m prior\u001b[38;5;241m.\u001b[39msample(torch\u001b[38;5;241m.\u001b[39mSize((num_prior_samples,)))\n\u001b[1;32m    658\u001b[0m theta_batch_shape, \u001b[38;5;241m*\u001b[39m_ \u001b[38;5;241m=\u001b[39m theta\u001b[38;5;241m.\u001b[39mshape\n\u001b[0;32m--> 659\u001b[0m simulation \u001b[38;5;241m=\u001b[39m \u001b[43msimulator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtheta\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    660\u001b[0m sim_batch_shape, \u001b[38;5;241m*\u001b[39msim_event_shape \u001b[38;5;241m=\u001b[39m simulation\u001b[38;5;241m.\u001b[39mshape\n\u001b[1;32m    662\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(theta, Tensor), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mParameters theta must be a `Tensor`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "Cell \u001b[0;32mIn[3], line 18\u001b[0m, in \u001b[0;36msimulator\u001b[0;34m(thetas)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_sims):\n\u001b[1;32m     17\u001b[0m     x_data_full \u001b[38;5;241m=\u001b[39m turin_sim(thetas[i, :])\n\u001b[0;32m---> 18\u001b[0m     \u001b[43mx_sim\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m compute_turin_summaries(x_data_full, delta_f\u001b[38;5;241m=\u001b[39m(B \u001b[38;5;241m/\u001b[39m (Ns \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m)))\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# x_sim = torch.squeeze(x_sim)\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x_sim\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The expanded size of the tensor (12) must match the existing size (9) at non-singleton dimension 0.  Target sizes: [12].  Tensor sizes: [9]"
     ]
    }
   ],
   "source": [
    "    N = 100\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    x_data_full = (\n",
    "        torch.tensor(np.load(\"../data/turin_obs.npy\")).float().reshape(N, 801).to(device)\n",
    "    )\n",
    "    B = 4e9\n",
    "    Ns = 801\n",
    "    x_obs = compute_turin_summaries(x_data_full, delta_f=(B / (Ns - 1)))\n",
    "    turin_sim = turin(B=B, Ns=801, N=N, tau0=0)\n",
    "\n",
    "    def simulator(thetas):\n",
    "        num_sims = thetas.shape[0]\n",
    "        x_data_full = torch.zeros(num_sims, N, 801)\n",
    "        x_sim = torch.zeros(num_sims, 12)\n",
    "        for i in range(num_sims):\n",
    "            x_data_full = turin_sim(thetas[i, :])\n",
    "            x_sim[i, :] = compute_turin_summaries(x_data_full, delta_f=(B / (Ns - 1)))\n",
    "        # x_sim = torch.squeeze(x_sim)\n",
    "        return x_sim\n",
    "\n",
    "    # test_theta = torch.tensor([10 ** (-8.4), 7.8e-9, 1e9, 2.8e-10])\n",
    "    # x_sim = simulator(test_theta)\n",
    "\n",
    "    prior = BoxUniform(\n",
    "        low=torch.tensor([1e-9, 1e-9, 1e7, 1e-10]),\n",
    "        high=torch.tensor([1e-8, 1e-8, 5e9, 1e-9]),\n",
    "    )\n",
    "    check_sbi_inputs(simulator, prior)\n",
    "\n",
    "    inference = NLE(prior)\n",
    "    proposal = prior\n",
    "    num_rounds = 5\n",
    "    num_sims = 500\n",
    "\n",
    "    # Prior predictive plots\n",
    "    num_prior_sims = 10\n",
    "    x_data_avg = torch.mean(x_data_full, dim=0)\n",
    "\n",
    "    # Create a figure\n",
    "    plt.figure()\n",
    "\n",
    "    # Plot observed average\n",
    "    plt.plot(x_data_avg.cpu().numpy(), color=\"red\", linewidth=3, label=\"Observed (avg)\")\n",
    "\n",
    "    # Draw some samples from the prior and plot their simulated averages\n",
    "    for i in range(num_prior_sims):\n",
    "        theta = prior.sample((1,))\n",
    "        x_prior_pred = turin_sim(theta)\n",
    "        x_prior_pred_avg = torch.mean(x_prior_pred, dim=0)\n",
    "        # Only add a legend label to the first prior draw, to avoid clutter\n",
    "        if i == 0:\n",
    "            plt.plot(\n",
    "                x_prior_pred_avg.cpu().numpy(),\n",
    "                linewidth=1,\n",
    "                alpha=0.3,\n",
    "                label=\"Prior draws\",\n",
    "            )\n",
    "        else:\n",
    "            plt.plot(x_prior_pred_avg.cpu().numpy(), alpha=0.3)\n",
    "\n",
    "    # A few labels and legend\n",
    "    plt.xlabel(\"Time index\")\n",
    "    plt.ylabel(\"Power (dB)\")\n",
    "    plt.title(\"Prior Predictive Checks\")\n",
    "    plt.legend()\n",
    "\n",
    "    # Save the figure\n",
    "    plt.savefig(\"figs/prior_predictive_checks_full_data.pdf\")\n",
    "\n",
    "    # Do Prior predictive checks on summaries\n",
    "    # bivariate plot of summaries\n",
    "    num_prior_sims = 500\n",
    "    prior_summs = torch.empty(num_prior_sims, 12)\n",
    "    for i in range(num_prior_sims):\n",
    "        theta = prior.sample((1,))\n",
    "        x_prior_pred = turin_sim(theta)\n",
    "        x_prior_summ = compute_turin_summaries(x_prior_pred, delta_f=(B / (Ns - 1)))\n",
    "        prior_summs[i, :] = x_prior_summ\n",
    "    # histogram plots\n",
    "    for i in range(12):\n",
    "\n",
    "        plt.figure()\n",
    "        plt.hist(prior_summs[:, i].cpu().numpy(), bins=30)\n",
    "        plt.plot(x_obs[i].cpu().numpy(), 0, \"ro\", label=\"Observed\")\n",
    "        plt.xlabel(f\"Summary {i}\")\n",
    "        plt.ylabel(\"Frequency\")\n",
    "        plt.title(f\"Prior Predictive Checks on Summary {i}\")\n",
    "        plt.savefig(f\"figs/prior_predictive_checks_summary_{i}.pdf\")\n",
    "\n",
    "    # plot bivariate scatter plots\n",
    "    for i in range(12):\n",
    "        for j in range(i + 1, 12):\n",
    "            plt.figure()\n",
    "            plt.scatter(\n",
    "                prior_summs[:, i].cpu().numpy(), prior_summs[:, j].cpu().numpy()\n",
    "            )\n",
    "            plt.plot(\n",
    "                x_obs[i].cpu().numpy(), x_obs[j].cpu().numpy(), \"ro\", label=\"Observed\"\n",
    "            )\n",
    "            plt.xlabel(f\"Summary {i}\")\n",
    "            plt.ylabel(f\"Summary {j}\")\n",
    "            plt.title(f\"Prior Predictive Checks on Summary {i} vs Summary {j}\")\n",
    "            plt.savefig(f\"figs/prior_predictive_checks_summary_{i}_vs_summary_{j}.pdf\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
